from http.client import responses
import os
import pandas as pd
import numpy as np
import requests
import time
from datetime import datetime
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from tqdm import tqdm

# ìœˆë„ìš° ê¸°ë³¸ í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False  # ìŒìˆ˜ ê¹¨ì§ ë°©ì§€

os.makedirs("data/raw", exist_ok=True)

def get_weather(api_key, base_date, base_time, nx=55, ny=124):
    url = "http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getVilageFcst"
    params = {
        'serviceKey': api_key,
        'numOfRows': '1000',
        'pageNo': '1',
        'dataType': 'JSON',
        'base_date': base_date,
        'base_time': base_time,
        'nx': nx,
        'ny': ny,
    }
    try:
        response = requests.get(url, params=params, timeout=5)
        response.raise_for_status()
        items = response.json()['response']['body']['items']['item']
        df = pd.DataFrame(items)
        return df
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {base_date} - {e}")
        return None

if __name__ == "__main__":
    api_key = "í‚¤ ì…ë ¥ë ¥"

    # ìˆ˜ì§‘ ê¸°ê°„: 2022-01-01 ~ 2025-06-30
    start_date = datetime.strptime("2022-01-01", "%Y-%m-%d")
    end_date = datetime.strptime("2025-06-30", "%Y-%m-%d")

    all_data = []

    for single_date in tqdm(pd.date_range(start=start_date, end=end_date)):
        base_date = single_date.strftime('%Y%m%d')
        df = get_weather(api_key, base_date, "0500", nx=55, ny=124)  # ë¶€í‰ ê¸°ì¤€

        if df is not None:
            all_data.append(df)

        time.sleep(0.3)  # ìš”ì²­ ê°„ ë”œë ˆì´ (API rate ì œí•œ ë°©ì§€ìš©)

    # ëª¨ë‘ í•©ì¹˜ê¸°
    if all_data:
        result_df = pd.concat(all_data, ignore_index=True)
        result_df.to_csv("weather-electricity-predict/data/raw/weather_all.csv", index=False)
        print("âœ… ì €ì¥ ì™„ë£Œ: weather_all.csv")
    else:
        print("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


#
def get_weather(api_key, base_date, base_time, nx=55, ny=124):
    url = "http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getVilageFcst"
    params = {
        'serviceKey': api_key,
        'numOfRows': '1000',
        'pageNo': '1',
        'dataType': 'JSON',
        'base_date': '20250709',  # 'YYYYMMDD'
        'base_time': '0500',  # '0500', '0800' ë“± 3ì‹œê°„ ë‹¨ìœ„
        'nx': 55,  # ì§€ì—­ Xì¢Œí‘œ (ì„œìš¸: 60)
        'ny': 124,  # ì§€ì—­ Yì¢Œí‘œ (ì„œìš¸: 127)
    }
    response = requests.get(url, params=params)
    items = response.json()['response']['body']['items']['item']
    df = pd.DataFrame(items)
    return df

if __name__ == "__main__":
    api_key = "í‚¤ ì…ë ¥ë ¥"
    today = datetime.now().strftime('%Y%m%d')
    df = get_weather(api_key, today, "0500")
    df.to_csv("weather-electricity-predict/data/raw/weather_sample.csv", index=False)


### ì¹´í…Œê³ ë¦¬ë³„ë¡œ í”¼ë²—í…Œì´ë¸” ë§Œë“¤ê¸°
pivot = df.pivot_table(
    index=["fcstDate", "fcstTime"],
    columns="category",
    values="fcstValue",
    aggfunc="first").reset_index()

pivot.head()

### íƒ€ì…ë³€í™˜ + ì‹œê°„ ì»¬ëŸ¼ ë§Œë“¤ê¸°

pivot['datetime'] = pd.to_datetime(pivot['fcstDate'] + pivot['fcstTime'], format='%Y%m%d%H%M')
pivot = pivot.sort_values('datetime')

#ìˆ«ìí˜• ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
for col in pivot.columns[2:-1]: #TNP, POPë“±
    pivot[col] = pd.to_numeric(pivot[col], errors='coerce')

## ê°„ë‹¨í•œ ì‹œê°í™”

plt.figure(figsize=[10,5])
plt.plot(pivot['datetime'], pivot['TMP'], label="ê¸°ì˜¨ (C)")
plt.plot(pivot["datetime"], pivot["POP"], label="ê°•ìˆ˜í™•ë¥  (%)")
plt.xticks(rotation=45)
plt.legend()
plt.title("ì‹œê°„ëŒ€ë³„ ê¸°ì˜¨ê³¼ ê°•ìˆ˜í™•ë¥ ")
plt.tight_layout()
plt.show()


###### ë°ì´í„°ê°€ ìµœê·¼ 3ì¼ì¹˜ ë°–ì— ì—†ì–´ì„œ ì¬ìˆ˜ì§‘ #######



import os
from datetime import datetime, timedelta
import requests


# API Key ë° ì €ì¥ ê²½ë¡œ ì„¤ì •
API_KEY = "í‚¤ ì…ë ¥"  
SAVE_DIR = "weather-electricity-predict/data/raw/weather"  # ì €ì¥ ê²½ë¡œ
os.makedirs(SAVE_DIR, exist_ok=True)

# ë‚ ì§œ ë²”ìœ„ ì„¤ì • (ì˜ˆ: 2022-01-01 ~ 2022-12-31)
start_date = datetime.strptime("20230101", "%Y%m%d")
end_date = datetime.strptime("20250701", "%Y%m%d")


def download_weather_file(date_str, stn=112):
    url = f"https://apihub.kma.go.kr/api/typ01/url/kma_sfcdd.php"
    params = {
        "tm": date_str,         # ë‚ ì§œ (YYYYMMDD)
        "stn": str(stn),        # ì§€ì  ì½”ë“œ (ì˜ˆ: 112 = ì¸ì²œ)
        "authKey": API_KEY
    }

    response = requests.get(url, params=params)

    if response.status_code == 200 and "#START7777" in response.text:
        filename = f"{SAVE_DIR}/{date_str}.txt"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(response.text)
        print(f"âœ… {date_str} ì €ì¥ ì™„ë£Œ")
    else:
        print(f"âŒ {date_str} - ë°ì´í„° ì—†ìŒ ë˜ëŠ” ì‘ë‹µ ì˜¤ë¥˜")

curr_date = start_date
while curr_date <= end_date:
    date_str = curr_date.strftime("%Y%m%d")
    download_weather_file(date_str, stn=112)  # ì¸ì²œ: 112ë²ˆ
    curr_date += timedelta(days=1)

import pandas as pd
import os


def parse_weather_txt(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    data_lines = [line for line in lines if not line.startswith('#') and line.strip() != '']

    if not data_lines:
        print(f"âŒ ë°ì´í„° ì—†ìŒ: {file_path}")
        return None

    cols = [
        "date", "stn", "ws_avg", "ws_day", "ws_max", "ws_tm1", "ws_max2", "ws_tm2", "ws_max3", "ws_tm3",
        "ta_avg", "ta_max", "ta_tm1", "ta_min", "ta_tm2",
        "td_avg", "ts_avg", "tg_min",
        "hm_avg", "hm_min", "hm_tm",
    ]

    values = data_lines[0].strip().split(',')
    if len(values) < len(cols):
        print(f"âš ï¸ ì—´ ê°œìˆ˜ ë¶€ì¡±: {file_path}")
        return None

    df = pd.DataFrame([values[:len(cols)]], columns=cols)
    return df


def parse_all_weather_files(directory):
    all_data = []

    for file in os.listdir(directory):
        if file.endswith(".txt"):
            file_path = os.path.join(directory, file)
            df = parse_weather_txt(file_path)
            if df is not None:
                all_data.append(df)

    if not all_data:
        print("ğŸ“­ ì½ì„ ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    merged_df = pd.concat(all_data, ignore_index=True)

    # ë‚ ì§œ ì •ë¦¬
    merged_df["date"] = pd.to_datetime(merged_df["date"], format="%Y%m%d")
    merged_df["yyyymm"] = merged_df["date"].dt.strftime("%Y-%m")

    # í•„ìš”í•œ ì»¬ëŸ¼ ìˆ«ìí˜• ë³€í™˜
    cols_to_float = ["ta_avg", "ta_min", "ta_max", "hm_avg"]
    for col in cols_to_float:
        merged_df[col] = pd.to_numeric(merged_df[col], errors="coerce")

    return merged_df


# ì‹¤í–‰
if __name__ == "__main__":
    data_dir = "weather-electricity-predict/data/raw/weather"  # ì—¬ê¸°ì— txt íŒŒì¼ ëª¨ì•„ë†“ì€ í´ë”
    df_all = parse_all_weather_files(data_dir)

    # ì›”ë³„ í‰ê· ê°’ìœ¼ë¡œ ì§‘ê³„
    df_monthly = df_all.groupby("yyyymm")[["ta_avg", "ta_min", "ta_max", "hm_avg"]].mean().reset_index()

    # ì €ì¥
    df_monthly.to_csv("weather-electricity-predict/data/processed/weather_monthly.csv", index=False)
    print("âœ… ì›”ë³„ ê¸°ìƒ ë°ì´í„° ì €ì¥ ì™„ë£Œ")

